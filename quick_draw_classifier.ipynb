{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "quick-draw-classifier.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/aashish2894/quick-draw-classifier/blob/master/quick_draw_classifier.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "IctoMK9Zeu9b",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Quick-Draw-Classifier"
      ]
    },
    {
      "metadata": {
        "id": "PE04gralet0n",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This classifies 100 classes"
      ]
    },
    {
      "metadata": {
        "id": "IlKEOsDqcsPZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "586fc82e-5614-40d5-9ade-54f30cb745e7"
      },
      "cell_type": "code",
      "source": [
        "!wget 'https://raw.githubusercontent.com/aashish2894/quick-draw-classifier/master/mini_classes.txt'"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Redirecting output to ‘wget-log’.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "lwp27iRvcygW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "f = open(\"mini_classes.txt\",\"r\")\n",
        "# And for reading use\n",
        "classes = f.readlines()\n",
        "f.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Pln6c5ZlnSW2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "classes = [c.replace('\\n','').replace(' ','_') for c in classes]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0094mW6TnT8Z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!mkdir data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ef30HquPr9nz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import urllib.request\n",
        "def download():\n",
        "  \n",
        "  base = 'https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/'\n",
        "  for c in classes:\n",
        "    cls_url = c.replace('_', '%20')\n",
        "    path = base+cls_url+'.npy'\n",
        "    print(path)\n",
        "    urllib.request.urlretrieve(path, 'data/'+c+'.npy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Xnn8dt7MsXop",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1717
        },
        "outputId": "0ec6bf29-bbe7-4e65-81fa-6044d823575c"
      },
      "cell_type": "code",
      "source": [
        "download() "
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/drums.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/sun.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/laptop.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/anvil.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/baseball%20bat.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/ladder.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/eyeglasses.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/grapes.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/book.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/dumbbell.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/traffic%20light.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/wristwatch.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/wheel.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/shovel.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/bread.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/table.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/tennis%20racquet.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/cloud.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/chair.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/headphones.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/face.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/eye.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/airplane.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/snake.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/lollipop.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/power%20outlet.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/pants.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/mushroom.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/star.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/sword.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/clock.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/hot%20dog.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/syringe.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/stop%20sign.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/mountain.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/smiley%20face.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/apple.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/bed.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/shorts.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/broom.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/diving%20board.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/flower.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/spider.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/cell%20phone.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/car.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/camera.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/tree.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/square.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/moon.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/radio.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/hat.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/pizza.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/axe.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/door.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/tent.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/umbrella.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/line.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/cup.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/fan.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/triangle.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/basketball.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/pillow.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/scissors.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/t-shirt.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/tooth.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/alarm%20clock.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/paper%20clip.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/spoon.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/microphone.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/candle.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/pencil.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/envelope.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/saw.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/frying%20pan.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/screwdriver.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/helmet.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/bridge.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/light%20bulb.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/ceiling%20fan.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/key.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/donut.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/bird.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/circle.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/beard.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/coffee%20cup.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/butterfly.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/bench.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/rifle.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/cat.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/sock.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/ice%20cream.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/moustache.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/suitcase.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/hammer.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/rainbow.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/knife.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/cookie.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/baseball.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/lightning.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/bicycle.npy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "DksTs6WLscbI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "import numpy as np\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow import keras \n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "s2wcBrODutUS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def load_data(root, vfold_ratio=0.2, max_items_per_class= 5000 ):\n",
        "    all_files = glob.glob(os.path.join(root, '*.npy'))\n",
        "\n",
        "    #initialize variables \n",
        "    x = np.empty([0, 784])\n",
        "    y = np.empty([0])\n",
        "    class_names = []\n",
        "\n",
        "    #load each data file \n",
        "    for idx, file in enumerate(all_files):\n",
        "        data = np.load(file)\n",
        "        data = data[0: max_items_per_class, :]\n",
        "        labels = np.full(data.shape[0], idx)\n",
        "\n",
        "        x = np.concatenate((x, data), axis=0)\n",
        "        y = np.append(y, labels)\n",
        "\n",
        "        class_name, ext = os.path.splitext(os.path.basename(file))\n",
        "        class_names.append(class_name)\n",
        "\n",
        "    data = None\n",
        "    labels = None\n",
        "    \n",
        "    #randomize the dataset \n",
        "    permutation = np.random.permutation(y.shape[0])\n",
        "    x = x[permutation, :]\n",
        "    y = y[permutation]\n",
        "\n",
        "    #separate into training and testing \n",
        "    vfold_size = int(x.shape[0]/100*(vfold_ratio*100))\n",
        "\n",
        "    x_test = x[0:vfold_size, :]\n",
        "    y_test = y[0:vfold_size]\n",
        "\n",
        "    x_train = x[vfold_size:x.shape[0], :]\n",
        "    y_train = y[vfold_size:y.shape[0]]\n",
        "    return x_train, y_train, x_test, y_test, class_names"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AeSxODNqvQq4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_train, y_train, x_test, y_test, class_names = load_data('data')\n",
        "num_classes = len(class_names)\n",
        "image_size = 28"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WTnRapb_vTcG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9fac9ee8-bd1c-4ab6-a2ad-9934c58c1e29"
      },
      "cell_type": "code",
      "source": [
        "print(len(x_train))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "400000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ALoZoGpDwfKk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "7a133c8f-3c10-46b9-f3dc-561187c6a83a"
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from random import randint\n",
        "%matplotlib inline  \n",
        "idx = randint(0, len(x_train))\n",
        "plt.imshow(x_train[idx].reshape(28,28)) \n",
        "print(class_names[int(y_train[idx].item())])"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "traffic_light\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPoAAAD4CAYAAADFJPs2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCPGVAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f092f4f4438>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "APAmkIPWxtwH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Reshape and normalize\n",
        "x_train = x_train.reshape(x_train.shape[0], image_size, image_size, 1).astype('float32')\n",
        "x_test = x_test.reshape(x_test.shape[0], image_size, image_size, 1).astype('float32')\n",
        "\n",
        "x_train /= 255.0\n",
        "x_test /= 255.0\n",
        "\n",
        "# Convert class vectors to class matrices\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aaAcMB08yEX8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 663
        },
        "outputId": "42ed891a-433d-4024-d090-805a131e8482"
      },
      "cell_type": "code",
      "source": [
        "# Define model\n",
        "model = keras.Sequential()\n",
        "model.add(layers.Convolution2D(16, (3, 3),\n",
        "                        padding='same',\n",
        "                        input_shape=x_train.shape[1:], activation='relu'))\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(layers.Convolution2D(32, (3, 3), padding='same', activation= 'relu'))\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(layers.Convolution2D(64, (3, 3), padding='same', activation= 'relu'))\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(layers.MaxPooling2D(pool_size =(2,2)))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(256, activation='relu'))\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(layers.Dense(128, activation='relu'))\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(layers.Dense(100, activation='softmax')) \n",
        "# Train model\n",
        "adam = tf.train.AdamOptimizer()\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=adam,\n",
        "              metrics=['top_k_categorical_accuracy'])\n",
        "print(model.summary())"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_6 (Conv2D)            (None, 28, 28, 16)        160       \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 28, 28, 16)        64        \n",
            "_________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2 (None, 14, 14, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 14, 14, 32)        4640      \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 14, 14, 32)        128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2 (None, 7, 7, 32)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 7, 7, 64)          18496     \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 7, 7, 64)          256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2 (None, 3, 3, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 576)               0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 256)               147712    \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 256)               1024      \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "batch_normalization_8 (Batch (None, 128)               512       \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 100)               12900     \n",
            "=================================================================\n",
            "Total params: 218,788\n",
            "Trainable params: 217,796\n",
            "Non-trainable params: 992\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "fVtfAioG0WR8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "f9c6e212-13c8-4e1a-e9d9-fddbfe141052"
      },
      "cell_type": "code",
      "source": [
        "model.fit(x = x_train, y = y_train, validation_split=0.1, batch_size = 64, verbose=2, epochs=7)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 360000 samples, validate on 40000 samples\n",
            "Epoch 1/7\n",
            " - 75s - loss: 0.5147 - top_k_categorical_accuracy: 0.9659 - val_loss: 0.7849 - val_top_k_categorical_accuracy: 0.9404\n",
            "Epoch 2/7\n",
            " - 75s - loss: 0.5066 - top_k_categorical_accuracy: 0.9667 - val_loss: 0.7806 - val_top_k_categorical_accuracy: 0.9418\n",
            "Epoch 3/7\n",
            " - 75s - loss: 0.4978 - top_k_categorical_accuracy: 0.9676 - val_loss: 0.8042 - val_top_k_categorical_accuracy: 0.9403\n",
            "Epoch 4/7\n",
            " - 75s - loss: 0.4901 - top_k_categorical_accuracy: 0.9681 - val_loss: 0.7888 - val_top_k_categorical_accuracy: 0.9403\n",
            "Epoch 5/7\n",
            " - 75s - loss: 0.4830 - top_k_categorical_accuracy: 0.9695 - val_loss: 0.8019 - val_top_k_categorical_accuracy: 0.9398\n",
            "Epoch 6/7\n",
            " - 75s - loss: 0.4741 - top_k_categorical_accuracy: 0.9700 - val_loss: 0.8028 - val_top_k_categorical_accuracy: 0.9387\n",
            "Epoch 7/7\n",
            " - 75s - loss: 0.4662 - top_k_categorical_accuracy: 0.9709 - val_loss: 0.8246 - val_top_k_categorical_accuracy: 0.9389\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f0926ef3cc0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "metadata": {
        "id": "UVeTQ9Cq2RV-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "44754522-34e8-4c38-f765-b6f3a22cde4f"
      },
      "cell_type": "code",
      "source": [
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test accuarcy: {:0.2f}%'.format(score[1] * 100))"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test accuarcy: 93.82%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "nP2KLrJT3wxL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "03ab48e3-1290-4792-e403-58198ac87be6"
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from random import randint\n",
        "%matplotlib inline  \n",
        "idx = randint(0, len(x_test))\n",
        "img = x_test[idx]\n",
        "plt.imshow(img.squeeze()) \n",
        "pred = model.predict(np.expand_dims(img, axis=0))[0]\n",
        "ind = (-pred).argsort()[:5]\n",
        "latex = [class_names[x] for x in ind]\n",
        "print(latex)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['door', 'cell_phone', 'book', 'bread', 'diving_board']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPoAAAD4CAYAAADFJPs2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/D+pOFGsczj1CgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f0926fab2e8>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "5FZ_-qq5B2xk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with open('class_names.txt', 'w') as file_handler:\n",
        "    for item in class_names:\n",
        "        file_handler.write(\"{}\\n\".format(item))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fxWQUoakB6YB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 887
        },
        "outputId": "57b46d4e-775c-4766-f28b-d8aeb3b9a5f9"
      },
      "cell_type": "code",
      "source": [
        "!pip install tensorflowjs "
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflowjs\n",
            "  Downloading https://files.pythonhosted.org/packages/4c/ba/a4372caa01427c179d271603fa305c9239ac2300d7b065ddc6fac46332f4/tensorflowjs-0.6.1-py3-none-any.whl\n",
            "Collecting numpy==1.15.1 (from tensorflowjs)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fe/94/7049fed8373c52839c8cde619acaf2c9b83082b935e5aa8c0fa27a4a8bcc/numpy-1.15.1-cp36-cp36m-manylinux1_x86_64.whl (13.9MB)\n",
            "\u001b[K    100% |████████████████████████████████| 13.9MB 2.5MB/s \n",
            "\u001b[?25hCollecting tensorflow==1.10.1 (from tensorflowjs)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/04/7e/a484776c73b1431f2b077e13801531e966113492552194fe721e6ef88d5d/tensorflow-1.10.1-cp36-cp36m-manylinux1_x86_64.whl (58.4MB)\n",
            "\u001b[K    100% |████████████████████████████████| 58.4MB 885kB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py==2.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflowjs) (2.8.0)\n",
            "Collecting keras==2.2.2 (from tensorflowjs)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/34/7d/b1dedde8af99bd82f20ed7e9697aac0597de3049b1f786aa2aac3b9bd4da/Keras-2.2.2-py2.py3-none-any.whl (299kB)\n",
            "\u001b[K    100% |████████████████████████████████| 307kB 12.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: six==1.11.0 in /usr/local/lib/python3.6/dist-packages (from tensorflowjs) (1.11.0)\n",
            "Requirement already satisfied: tensorflow-hub==0.1.1 in /usr/local/lib/python3.6/dist-packages (from tensorflowjs) (0.1.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.10.1->tensorflowjs) (1.1.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.10.1->tensorflowjs) (0.2.0)\n",
            "Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.10.1->tensorflowjs) (0.5.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.10.1->tensorflowjs) (0.7.1)\n",
            "Requirement already satisfied: setuptools<=39.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.10.1->tensorflowjs) (39.1.0)\n",
            "Requirement already satisfied: tensorboard<1.11.0,>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.10.1->tensorflowjs) (1.10.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.10.1->tensorflowjs) (1.15.0)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.10.1->tensorflowjs) (3.6.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.10.1->tensorflowjs) (0.31.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras==2.2.2->tensorflowjs) (3.13)\n",
            "Collecting keras-applications==1.0.4 (from keras==2.2.2->tensorflowjs)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/54/90/8f327deaa37a71caddb59b7b4aaa9d4b3e90c0e76f8c2d1572005278ddc5/Keras_Applications-1.0.4-py2.py3-none-any.whl (43kB)\n",
            "\u001b[K    100% |████████████████████████████████| 51kB 9.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.2->tensorflowjs) (0.19.1)\n",
            "Collecting keras-preprocessing==1.0.2 (from keras==2.2.2->tensorflowjs)\n",
            "  Downloading https://files.pythonhosted.org/packages/71/26/1e778ebd737032749824d5cba7dbd3b0cf9234b87ab5ec79f5f0403ca7e9/Keras_Preprocessing-1.0.2-py2.py3-none-any.whl\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.11.0,>=1.10.0->tensorflow==1.10.1->tensorflowjs) (3.0.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.10 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.11.0,>=1.10.0->tensorflow==1.10.1->tensorflowjs) (0.14.1)\n",
            "\u001b[31mtensorflow 1.10.1 has requirement numpy<=1.14.5,>=1.13.3, but you'll have numpy 1.15.1 which is incompatible.\u001b[0m\n",
            "Installing collected packages: numpy, tensorflow, keras-applications, keras-preprocessing, keras, tensorflowjs\n",
            "  Found existing installation: numpy 1.14.6\n",
            "    Uninstalling numpy-1.14.6:\n",
            "      Successfully uninstalled numpy-1.14.6\n",
            "  Found existing installation: tensorflow 1.11.0rc2\n",
            "    Uninstalling tensorflow-1.11.0rc2:\n",
            "      Successfully uninstalled tensorflow-1.11.0rc2\n",
            "  Found existing installation: Keras-Applications 1.0.5\n",
            "    Uninstalling Keras-Applications-1.0.5:\n",
            "      Successfully uninstalled Keras-Applications-1.0.5\n",
            "  Found existing installation: Keras-Preprocessing 1.0.3\n",
            "    Uninstalling Keras-Preprocessing-1.0.3:\n",
            "      Successfully uninstalled Keras-Preprocessing-1.0.3\n",
            "  Found existing installation: Keras 2.1.6\n",
            "    Uninstalling Keras-2.1.6:\n",
            "      Successfully uninstalled Keras-2.1.6\n",
            "Successfully installed keras-2.2.2 keras-applications-1.0.4 keras-preprocessing-1.0.2 numpy-1.15.1 tensorflow-1.10.1 tensorflowjs-0.6.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qxfpnR16B8Jo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "637fe48d-b054-4f43-f4bf-6991d856cc3e"
      },
      "cell_type": "code",
      "source": [
        "model.save('keras.h5')"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "DZ3Mdm_3CWkJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "db0efc5f-0a75-4e9e-b825-d8aa849f5e82"
      },
      "cell_type": "code",
      "source": [
        "!mkdir model\n",
        "!tensorflowjs_converter --input_format keras keras.h5 model/"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "du-WOYcqCdvU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!cp class_names.txt model/class_names.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eRfY4RodCi3i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "b5abf8c3-d506-4595-821d-c0c362f41448"
      },
      "cell_type": "code",
      "source": [
        "!zip -r model.zip model "
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  adding: model/ (stored 0%)\n",
            "  adding: model/model.json (deflated 90%)\n",
            "  adding: model/group1-shard1of1 (deflated 7%)\n",
            "  adding: model/class_names.txt (deflated 41%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5bLgIJCDClvd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('model.zip')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dZCugs24CoJy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}